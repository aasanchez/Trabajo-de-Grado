\chapter{Clasificador Neuronal de Permutación de Códigos (PCNC)}\label{cap:PCNC}
El capítulo que inicia está dedicado al segundo clasificador neuronal utilizado para la implementación del SVT. Este clasificador llamado
PCNC ha sido introducido en la Sección \ref{sec:selDeClasificadores} teniendo diferencias
sustanciales con el clasificador LIRA pero también algunas
similitudes. A continuación en la siguiente sección se describe
detenidamente la estructura del PCNC y los procesos que lleva a
cabo. En la sección posterior se aborda el proceso de entrenamiento
del mismo. En la Sección \ref{sec:PCNCdistor} se explican las distorsiones probadas con
las base de datos utilizadas con el PCNC mientras que la Sección \ref{sec:PCNCdiscu} y última dedica unas líneas a la discusión sobre este clasificador respecto a la tarea de la que se ocupa.

\section{Estructura}\label{sec:PCNCestructura}
El PCNC está basado en la estructura genérica del paradigma \emph{Associative Projective Neural Networks} (APNN) descrita en \cite{Kussul1991ANNIE,Kussul1991NNA}. Dicho paradigma incluye al \emph{clasificador de umbral aleatorio} \cite{Kussul1994AUIC,Kussul1994CS}, al \emph{clasificador neuronal de subespacio aleatorio} \cite{Kussul2001}, al clasificador LIRA \cite{Kussul2002ICVI} y al \emph{clasificador neuronal de permutación de códigos} (PCNC\footnote{PCNC son las siglas de permutative code neural classifier.}) \cite{Kussul2003IJCNN}. El PCNC al igual que el clasificador neuronal LIRA trabaja con imágenes en escala de grises.

La estructura del PCNC consta de tres partes que trabajan en forma seriada, estas son un extractor de propiedades, un codificador y un clasificador neuronal (Fig. \ref{fig:PCNC}).

\begin{figure}[h]
\begin{center} 
\includegraphics[width=\textwidth]
{figuras/PCNC.png}
\end{center}
\caption[Estructura del PCNC.]{Diagrama a bloques de la estructura del PCNC mostrando los elementos principales de intercambio entre ellos.}\label{fig:PCNC}
\end{figure}

De forma muy general el PCNC inicia su trabajo cuando una imagen en
escala de grises es presentada a la entrada del extractor de propiedades, las propiedades extraídas por este último son presentadas al codificador que las transforma en un vector binario de gran dimensión, vector que por último es dado al clasificador neuronal de una capa para ser procesado por éste, ya sea para propósitos de entrenamiento, de prueba o para reconocimiento de alguna clase previamente entrenada.

\subsection{Extractor de propiedades}\label{ssec:PCNCextractor}
El extractor de propiedades (Fig. \ref{fig:extractor}) inicia su trabajo con una imagen en escala de grises. Éste selecciona sobre la imagen una serie de puntos específicos (Fig. \ref{fig:puntosEspecificos}). Muchas formas de selección de estos puntos específicos pueden ser utilizadas, lo importante es que estos puntos representen las propiedades de la imagen que intervengan en su clasificación o diferenciación entre otras imágenes distintas a ser reconocidas. Dos métodos para definir los puntos específicos son por umbral de brillo y por extracción de contornos. Ambos métodos requieren de la selección de un umbral de brillo determinado $B$. Para el primer método, los puntos específicos de la imagen serán todos aquellos píxeles cuyo brillo $b_{ij}$ sea mayor que $B$. Para el método de contorno se seleccionan todos aquellos puntos en donde el gradiente del brillo, es decir los contornos, sean mayores que el umbral $B$; con esta última selección por umbral se logra eliminar considerablemente el ruido de la imagen de contorno.

\begin{figure}[h]
\begin{center} 
\includegraphics[width=0.8\textwidth]
{figuras/ExtractorDePropiedades.png}
\caption[Procesos del extractor de propiedades.]{Procesos del extractor de propiedades, su interrelación, así como sus entradas y salidas.}
\label{fig:extractor}
\end{center}
\end{figure}

\begin{figure}
[ht]
\centering
%\renewcommand{\thesubfigure}{\alph{subfigure})}
\setcounter{subfiggroup}{1}
\subfloat[]{\label{fig:imagenNormalizadaCono}\includegraphics[width=0.18\textwidth]{figuras/PCNC/sp/cono_0000.png}}
\subfloat[]{\label{fig:imagenNormalizadaEje}\includegraphics[width=0.18\textwidth]{figuras/PCNC/sp/eje_de_rotor_0000.png}}
\subfloat[]{\label{fig:imagenNormalizadaTerminal}\includegraphics[width=0.18\textwidth]{figuras/PCNC/sp/terminal_de_cable_0000.png}}
\\ %break current line
\setcounter{subfigure}{0} %Reset the subfigure counter 
\addtocounter{subfiggroup}{1} %My own counter is increased
\subfloat[]{\label{fig:imagenNormalizadaConoSobel}\includegraphics[width=0.18\textwidth]{figuras/PCNC/sp/cono_0000sp.png}}
\subfloat[]{\label{fig:imagenNormalizadaEjeSobel}\includegraphics[width=0.18\textwidth]{figuras/PCNC/sp/eje_de_rotor_0000sp.png}}
\subfloat[]{\label{fig:imagenNormalizadaTerminalSobel}\includegraphics[width=0.18\textwidth]{figuras/PCNC/sp/terminal_de_cable_0000sp.png}}
\caption[Selección de puntos específicos.]{Selección de puntos
  específicos con el método de umbral de bordes. Se parte de una imagen normalizada y se aplica un
  operador de extracción de bordes Sobel. Se seleccionan aquellos puntos resultantes que son mayores que el umbral predefinido $B$. Fila superior. Imágenes
  normalizada originales. Fila inferior. Resultado de la selección de
  los puntos específicos sobre las imágenes respectivas de arriba, todos los píxeles negros en la imagen son puntos específicos seleccionados.}
\label{fig:puntosEspecificos}
\end{figure}

Para el presente trabajo, de acuerdo a la naturaleza de las imágenes y
las piezas que éstas contienen descritas en el Capítulo \ref{cap:disenoSVT}, se ha
utilizado el método de extracción de contornos mediante un operador Sobel \cite{sobel1968}. El método de umbral de brillo aplicado en imágenes
relativamente grandes como las utilizadas en este trabajo
($100\times 100$ o $150\times 150$) resulta en grandes cantidades de
puntos específicos que implican el incremento masivo de recursos
necesarios para el procesamiento de éstos y para las posteriores etapas del
PCNC. 

Para cada punto específico se define un rectángulo de dimensión $w\times h$ en cuyo centro está precisamente este punto (Fig. \ref{fig:propiedades}). Desde dentro de éste rectángulo se extraen múltiples propiedades de la imagen mediante el procedimiento explicado a continuación. Un conjunto de puntos positivos $p$ y negativos $n$ determinan cada una de las propiedades dentro del rectángulo. Estos puntos se distribuyen aleatoriamente dentro del rectángulo y su número es fijo para toda la estructura. Cada punto $P_{rs}$ tiene asociado un umbral $T_{rs}$ el cuál se define aleatoriamente en el rango:
\begin{equation}
T_{min}\leq T_{rs}\leq T_{max}
\end{equation}
Los puntos positivos serán activos siempre que su brillo sea:
\begin{equation}
b_{rs}\geq T_{rs}.
\end{equation}
Los puntos negativos serán activos siempre que su brillo sea:
\begin{equation}
b_{rs}\leq T_{rs}.
\end{equation}
Una determinada propiedad existirá en el rectángulo si todos los
puntos tanto positivos como negativos se encuentran activos.

\begin{figure}[h]
\begin{center} 
\includegraphics[width=0.75\textwidth]
{figuras/unaPropiedadSobreUnPuntoEspecifico.png}
\end{center}
\caption[Extracción de propiedades.]{Extracción de propiedades en la imagen. Primero se definen $S$ propiedades. Cada una  mediante $p$ puntos positivos y $n$ puntos negativos aleatoriamente distribuidos sobre un rectángulo de $w\times h$ píxeles. A la izquierda se ilustran ejemplos de estas propiedades con $p=4$ y $n=5$. En el cuadro principal se muestran los puntos específicos de una imagen. Para cada uno de estos puntos se prueba la existencia de las $S$ propiedades. En la imagen se muestra el proceso de búsqueda de la propiedad $F_{k}$.}\label{fig:propiedades}
\end{figure}

Se procura que ninguno de estos rectángulos de búsqueda de
propiedades en la imagen salga de la misma. Debe recordarse que una
característica de las imágenes que se busca reconocer en este trabajo (imágenes
normalizadas) no tienen puntos de interés en las orillas. Sin embargo
si se elijen relativamente grandes los parámetros de ventana $w$ y $h$
con respecto a las dimensiones de la imagen $W$ y $H$ se tendrá más
probabilidad de que existan rectángulos que salgan de los límites de
la imagen, esto se hace más probable si existen puntos específicos
cerca de las orillas. Considerando lo anterior se expande la imagen $w/2$ píxeles a cada lado y $h/2$ píxeles arriba y abajo con color
blanco, es decir, significando ausencia de todo punto específico
posible y evitando que cualquiera de estos rectángulos salga de la imagen ampliada. 

Se utilizan muchas propiedades distintas $F_{i} \; | \; i\in [1,S]$. Donde
$S$ es por lo general del orden de unidades de millar. El extractor de propiedades
examina las $S$ propiedades para cada uno de los puntos específicos
definidos. Todas las propiedades extraídas de todos los puntos específicos definidos son entregados al codificador.

\subsection{Codificador}\label{ssec:PCNCcodificador}
El codificador (Fig. \ref{fig:codificador}) transforma las propiedades dadas por el extractor de propiedades a un vector
binario:
\begin{equation}
V=\left\{v_{i} \; | \; v_{i}=\{0,1\}, \; i\in(1,N)\right\},
\end{equation}

\begin{figure}[h]
\begin{center} 
\includegraphics[width=\textwidth]
{figuras/codificador.png}
\end{center}
\caption[Procesos del codificador.]{Principales procesos que lleva a cabo el codificador así como sus entradas y salidas.}\label{fig:codificador}
\end{figure}


Para cada propiedad extraída $F_{k}$ el
codificador crea un vector adicional binario:
\begin{equation}
U_{k}=\left\{u_{i} \; | \; u_{i}=\{0,1\}, \: i\in(1,N)\right\},
\end{equation}
Este vector contiene K 1's, donde $K\ll N$, al menos mil veces menor. Un procedimiento aleatorio que se explica más tarde es utilizado para elegir las posiciones de los unos en el vector U para cada propiedad $F_{k}$. Este procedimiento genera la lista de posiciones de unos para cada característica y salva todas estas listas en memoria no volátil. El vector $U_{k}$ es llamado \emph{máscara} de la propiedad $F_{k}$.

En la siguiente etapa del proceso de codificación se hace necesario
transformar el vector auxiliar $U$ al nuevo vector $U^{*}$ el cual
corresponde a la propiedad localizada en la imagen. Esta
transformación se hace mediante permutaciones de los componente del
vector $U$. El número de permutaciones depende de la localización de la propiedad en la imagen. Las permutaciones correspondientes a las direcciones horizontal ($X$) y vertical ($Y$) son permutaciones diferentes.

Una permutación de $m$ elementos $P^{m}$ puede ser representada como un vector $m$-dimensional. Para aplicar esta permutación a un vector éste debe ser de dimensión $m$. En términos formales:

\begin{equation}
P^{m}(V)=V' \; | \; V'=\{v'_{i}\} \; , \; v'_{p_{i}}=v_{i} \; , \quad P,V,V'\in \Re^{m}
\end{equation}

Lo cual significa que el resultado de aplicar la permutación $P^{m}$ a un vector $V$ resulta en un nuevo vector $V'$ cuyos componentes se definen tomando cada componente $v_{i}$ de $V$ y colocándolo en la posición $p_{i}$ de $V'$, es decir, a la que apunta el índice correspondiente del vector de permutación $P^{m}$. En la Fig. \ref{fig:permutacion} se ilustra un ejemplo gráfico simple a este respecto.

\begin{figure}[h]
\begin{center} 
\includegraphics[width=0.5\textwidth]
{figuras/permutacionYsuRepresentacion.png}
\end{center}
\caption[Permutación y su representación.]{Permutación y su representación sobre un vector. Se ilustra una permutación $P^{6}$ como un vector. El resultado de aplicar esta permutación sobre un vector $V$ se ilustra a la derecha. Cada elemento $v_{i}$ de $V$ es reordenado en la posición señalada por la componente correspondiente de $P^{6}$, dando como resultado un nuevo vector $V'$ con los mismos elementos de $V$ pero en orden distinto.}\label{fig:permutacion}
\end{figure}

\subsubsection{Codificación de las propiedades}
El problema a resolver es obtener códigos binarios de las propiedades extraídas los
cuales tengan correlación fuerte si la distancia entre las
localizaciones de las propiedades es pequeña y tengan correlación
débil o no tengan ninguna si esta distancia es grande. Por ejemplo, si una misma propiedad $F_{k}$ se extrae tanto en un extremo de la pieza en la imagen como en el otro extremo entonces éstas deben ser codificadas como vectores binarios distintos $U^{*}_{k1}$ y $U^{*}_{k2}$, existiendo entre estos correlación débil o ausencia alguna de correlación. En el caso de que la misma propiedad sea encontrada en puntos vecinos entonces estas deben ser codificadas con los mismos vectores $U^{*}_{k3}$ y $U^{*}_{k4}$. Esta propiedad que se acaba de describir permite que el sistema de reconocimiento sea insensible a pequeños desplazamientos de los objetos en la imagen.

Para codificar la localización de la propiedad $F_{k}$ en la imagen es necesario definir y dar valor a la distancia de correlación $D_{c}$. Sea la propiedad $F_{k}$ detectada en dos puntos distintos $P_{1}(x_{1},y_{1})$ y $P_{2}(x_{2},y_{2})$, sean $U^{*}_{P1}$ y $U^{*}_{P2}$ los vectores binarios que codifican a $F_{k}$ para estos puntos respectivamente y sea $d$ la distancia euclidiana entre estos puntos dada por:
\begin{equation}
d=\sqrt{(x_{2}-x_{1})^{2}+(y_{2}-y_{1})^{2}}
\end{equation}
Se requiere que:
\begin{equation}
d < D_{c} \Rightarrow U^{*}_{P1} \;\mbox{y}\; U^{*}_{P2} \quad\mbox{estén correlacionados y,} 
\end{equation}
\begin{equation}
d \geq D_{c} \Rightarrow U^{*}_{P1} \;\mbox{y}\; U^{*}_{P2} \quad\mbox{no estén correlacionados.}
\end{equation}

Para buscar cumplir con estas propiedades se calculan los siguientes valores para una propiedad detectada $F_{k}$ en un punto $P(i,j)$:

\begin{eqnarray}
X=i/D_{c},\nonumber\\
E(X)=int\left( X \right) ,\label{eq:permX}\\
R(X)=i-E(X)\cdot D_{c},\nonumber
\end{eqnarray}

\begin{eqnarray}
Y=j/D_{c},\nonumber\\
E(Y)=int\left( Y \right),\label{eq:permY}\\
R(Y)=j-E(Y)\cdot D_{c},\nonumber
\end{eqnarray}

\begin{equation}
p_{x}=int\left(\frac{R(X)}{D_{c}}N \right),
\label{eq:permFracX}
\end{equation}
\begin{equation}
p_{y}=int\left( \frac{R(Y)}{D_{c}}N \right),
\label{eq:permFracY}
\end{equation}

donde $int()$ es la función entero. Por lo tanto $E(X)$ y $E(Y)$ son las partes enteras de $X$ y $Y$ respectivamente y $R(X)$ y $R(Y)$ son las partes fraccionarias de $X$ y $Y$ respectivamente.

La máscara (vector $U_{k}$) de la propiedad $F_{k}$ se considera como un código de esta propiedad localizado en el punto origen de la imagen: $O(0,0)$. Se definen las permutaciones $\mathbf{P_{x}}$ y $\mathbf{P_{y}}$ como requisito para obtener los códigos correspondientes a las propiedades existentes en cualquier punto de la imagen fuera del origen. En general, para obtener el código de la propiedad $F_{k}$ perteneciente al punto $P(i,j)$ se procede de la siguiente forma:

\begin{enumerate}
\item Primero se trata el desplazamiento horizontal, para lo cual se aplica $E(X)$ veces la permutación $\mathbf{P_{x}}$ al vector $U_{k}$, después se aplica la misma permutación una vez más pero solamente a los primeros $p_{x}$ componentes del vector $U_{k}$.
\item Segundo, se trata el desplazamiento vertical de forma análoga. Se aplica la permutación $\mathbf{P_{y}}$ $E(Y)$ veces con una permutación adicional para los primeros $p_{y}$ componentes de $U_{k}$.
\end{enumerate}

\subsubsection{Ejemplo de permutaciones}
El procedimiento anterior se ilustra con un ejemplo para facilitar su comprensión. La dimensión del vector $U$ y los valores $x$ y $y$ del punto $P$ se eligen pequeños con el propósito de dar claridad al proceso. Tomemos como parámetros del PCNC $D_{c}=6$ y $N=8$ y sean $\mathbf{P_{x}}$ y $\mathbf{P_{y}}$ dos permutaciones de dimensión $N$. 

Supóngase detectada la propiedad $F$ en el punto $P(10,14)$ y sea el vector $U$ la máscara correspondiente a esta propiedad. La tarea consiste en codificar $U$ en un nuevo vector $U^{*}$ atendiendo a las coordenadas del punto $P$. Como primer paso se aplican \eqref{eq:permX}, \eqref{eq:permY}, \eqref{eq:permFracX} y \eqref{eq:permFracY} resultando: $E(X)=1$, $E(Y)=2$, $p_{x}=5$ y $p_{y}=2$. Se aplica a continuación $E(X)$=1 permutación $\mathbf{P_{x}}$ al vector $U$ (Fig. \ref{fig:permutacionesX}) y luego al resultado ($U_{1}$) se aplica una permutación adicional únicamente a los primeros $p_{x}=5$ componentes obteniendo con esto el vector $U'$, todas las componentes que no sean definidas mediante la permutación parcial se copian del vector anterior correspondiente no importante si fueron permutados o no. Con el proceso anterior tenemos las siguientes trayectorias de ejemplo: $u_{1} \rightarrow u_{1,3} \rightarrow u'_{4}$, $u_{2} \rightarrow u_{1,7} \rightarrow$ se elimina y $u_{8} \rightarrow u_{1,5} \rightarrow u'_{8},u'_{5}$. Tenemos que para el primer ejemplo el valor de $u_{1}$ es permutado dos veces y termina en $u'_{4}$. Para el segundo caso $u_{2}$ se permuta una sola vez a $u_{1,7}$ y luego se ignora porque a la componente $7$ es menor que $p_{x}=5$ y por que la componente correspondiente en $U'$ ya ha sido ocupada por $u_{7}$. Para el tercer caso $u_{8}$ se permuta las dos veces pero adicionalmente es copiado a la componente $u'_{5}$ pues luego de permutar los primeros $5$ elementos de $U'$ queda vacía. 
\begin{figure}[h]
\begin{center} 
\includegraphics[width=0.75\textwidth]
{figuras/permutacionesXejemplo.png}
\end{center}
\caption[Permutaciones X.]{Ejemplo de permutaciones $\mathbf{P_{X}}$ sobre el vector $U$ con $E(X)=1$ y $p_{x}=5$. Se aplica una vez la permutación a todo el vector y una vez más sólo a los primeros cinco componentes del mismo. En este sentido las líneas punteadas representan cambios que no deben realizarse.}\label{fig:permutacionesX}
\end{figure}

En este ejemplo se han dado los tres casos posibles que pueden ocurrir, sin embargo debe tenerse en cuenta que de acuerdo a la naturaleza práctica de los vectores máscaras ($U$) que tienen dimensión $N$ muy grande y sus componentes son mayoritariamente ceros, los casos especiales de eliminación ocurren muy rara vez como se explicará.

Una vez habiendo realizado las permutaciones $X$, realizamos las permutaciones $Y$ con el mismo procedimiento, sólo que ahora lo haremos con el vector $U'$ y aplicaremos la permutación $\mathbf{P_{y}}$ y los parámetros $E(Y)$ y $p_{y}$. En la Fig. \ref{fig:permutacionesY} se muestra gráficamente este procedimiento. El resultado de esta permutación es el resultado de ambas permutaciones aplicadas sobre el vector máscara $U$ de la propiedad $F$ y le llamamos vector $U^{*}$. Este vector codifica la propiedad $F$ en la ubicación del punto $P(10,14)$ de la imagen correspondiente.

\begin{figure}[h]
\begin{center} 
\includegraphics[width=0.75\textwidth]
{figuras/permutacionesYejemplo.png}
\end{center}
\caption[Permutaciones Y.]{Ejemplo de permutaciones $\mathbf{P_{Y}}$ aplicado sobre el vector resultante de las permutaciones $\mathbf{P_{X}}$ con $E(Y)=2$ y $p_{y}=2$. La permutación se aplica dos veces a todo el vector y una vez más solamente a los primeros dos elementos del mismo. Las líneas punteadas de la última permutación indican cambios que no deben realizarse.}\label{fig:permutacionesY}
\end{figure}


\subsubsection{Propiedades de las permutaciones}
Consideremos ahora las propiedades de las permutaciones descritas. Supóngase que la propiedad $F_{k}$ ha sido detectada en dos puntos $P_{1}(x_{1},y_{1})$ y $P_{2}(x_{2},y_{2})$tales que $x_{1}\neq x_{2}$ y $y_{1}\neq y_{2}$. Sea $U_{k}$ la máscara correspondiente para esta propiedad. Se definen $d_{x}$ y $d_{y}$ como:
\begin{equation}
d_{x}=|x_{2}-x_{1}|,
\end{equation} 
\begin{equation}
d_{y}=|y_{2}-y_{1}|
\end{equation} 

Suponiendo que $dx\neq 0$, luego de realizar las permutaciones horizontales ($\mathbf{P_{x}}$) los vectores correspondientes $U_{1}$ y $U_{2}$ serán distintos. Sea $\Delta n$ la diferencia en el número de 1's entre los vectores. Puede mostrarse que el valor promedio de $\Delta n$ puede calcularse de forma aproximada con:

\begin{equation}
\Delta n \approx \frac{K}{D_{c}}d_{x} 
\end{equation}

donde $K$ es el número de unos del vector auxiliar binario $U$ de la propiedad $F_{k}$. Luego de las permutaciones verticales ($\mathbf{P_{y}}$) los vectores resultantes correspondientes $U^{*}_{1}$ y $U^{*}_{2}$ tendrán diferencias que pueden ser estimadas por:

\begin{equation}
\overline{\Delta n} \approx K\left(1-\left(1-\frac{d_{x}}{D_{c}}\right)\left(1-\frac{d_{y}}{D_{c}}\right)\right), \; 
1>\overline{\Delta n}>0.
\end{equation}

Por lo anterior los vectores $U^{*}_{1}$ y $U^{*}_{2}$ estarán correlacionados solamente si se cumple $d_{x}<D_{c}$ y $d_{y}<D_{c}$. La correlación se incrementará si $d_{x}$ y $d_{y}$ se decrementan.

Puede verse en la Fig. \ref{fig:permutacionesXY} que distintos componentes del vector $U$ pueden pretender quedar en la misma posición luego de realizar las permutaciones. Por ejemplo, luego de las permutaciones $\mathbf{P_{x}}$ el componente $u_{8}$ ocupa dos posiciones en $U'$ o luego de aplicar ambas permutaciones el componente $u_{6}$ termina en dos posiciones y el $u_{8}$ en tres. Estos eventos son indeseables y no son un problema para el PCNC pues la probabilidad de que tales eventos indeseables sucedan está relacionada inversamente a la dimensión de $N$ y a la relación $N/K$ y atendiendo a los valores grandes de $N$ y pequeños para $K$ la probabilidad de estos eventos es menor de 0.01\% \cite{Kussul2006IEEE}.

\begin{figure}[h]
\begin{center} 
\includegraphics[width=0.75\textwidth]
{figuras/permutacionesXYejemplo.png}
\end{center}
\caption[Permutaciones XY.]{Resultados obtenidos al aplicar las permutaciones $\mathbf{P_{x}}$ sobre el vector $U$ y luego la permutación $\mathbf{P_{y}}$ a ese resultado $U'$. En la figura se muestra el orden final de las componentes del vector $U$ dentro del vector final $U^{*}$.}\label{fig:permutacionesXY}
\end{figure}

\subsubsection{Vector código $\mathbf{V}$ }
Una vez calculados todos los vectores $U^{*}_{r}$ de todas las propiedades detectadas en la imagen se crea el vector código definido como:

\begin{equation}
V=\left\{v_{i}\ \; | \; v_{i}= \bigwedge u^{*}_{ri} \; , \; i\in(1,N)\right\}
\label{eq:vectorCodigo}
\end{equation}

donde $\bigwedge$ es el símbolo de la disyunción, $u^{*}_{ri}$ es el $i$-ésimo componente del vector $U^{*}_{r}$, vector que es el corresponde a la propiedad detectada $F_{r}$.

Al utilizar números aleatorios independientes para la generación de las máscaras se logra que este proceso de codificación produzca representaciones mayoritariamente independientes para todas las propiedades. La única pero débil influencia entre las distintas propiedades aparece cuando se absorbe algún \emph{1} en la disyunción, Eq. \eqref{eq:vectorCodigo}.

\subsubsection{Adelgazador dependiente de contexto (CDT)}\label{sssec:CDT}
Para poder reconocer alguna pieza en una imagen se hace necesario
utilizar combinación de propiedades, es decir, combinar la existencia
de ciertas propiedades con la ausencia de otras. Para lograr este
propósito de combinación de propiedades se ha utilizado con éxito el
CDT\footnote{Llamado así por ser las siglas en inglés de Context
  Dependent Thinning.} o \emph{Adelgazador dependiente de contexto.}
\cite{Rachkovskij2001}. El CDT ha sido desarrollado en base al proceso
de normalización de vectores \cite{Artikutsa1991}. Si bien existen
diversos procedimientos de implementación del CDT en este trabajo se
utiliza el procedimiento ilustrado en la
Fig. \ref{fig:permutacionesQ}, el cuál requiere de un número entero
$q$ como parámetro de entrada y consiste en lo siguiente:

\begin{enumerate}
\item Se genera una nueva permutación $\mathbf{Q}$ de dimensión $N$ la cuál es independiente de $\mathbf{P_{x}}$ y $\mathbf{P_{y}}$.
\item Se prueba cada componente $v_{i}$ del vector $V$,
  si $v_{i}=0$ no se hace nada
  si $v_{i}=1$ se considera la trayectoria de este componente individual durante $q$ permutaciones $\mathbf{Q}$. Si esta trayectoria pasa por al menos un elemento \emph{1} del vector $V$, el valor de $v_{i}$ se hace 0.
\item Al vector resultante se le llama $V'$.
\end{enumerate}

Un ejemplo gráfico de lo anterior se tiene en la Fig. \ref{fig:permutacionesQ} donde $q=4$. La permutación $\mathbf Q$ se representa por las flechas. Para el elemento $v_{1}$ se sigue la trayectoria indicada por la permutación la cuál es: $v_{1} \rightarrow v_{7} \rightarrow v_{8} \rightarrow v_{5}$, si cualquiera de las componentes $v_{7}$, $v_{8}$ o $v_{5}$ es igual a $1$ entonces $v_{1}=0$. Lo mismo se hace para todos los elementos de $V$, construyéndose un nuevo vector sin alterar el vector original.

\begin{figure}[h]
\begin{center} 
\includegraphics[width=0.75\textwidth]
{figuras/permutacionesQejemplo.png}
\end{center}
\caption[Permutaciones Q.]{Aplicación de $q$ permutaciones $\mathbf{Q}$ sobre el vector $V$.}\label{fig:permutacionesQ}
\end{figure}

El número $q$ es un parámetro de reconocimiento del sistema. Una vez que se aplica el CDT al vector $V$ se ha cumplido con el proceso correspondiente del codificador. El vector $V'$ de dimensión $N$ representa el código de la imagen presentada originalmente al extractor de propiedades. Este resultado está listo para ser pasado al clasificador neuronal.

\subsection{Clasificador neuronal}\label{ssec:PCNCnc}
En la Sección \ref{sec:selDeClasificadores} se ha mencionado y hecho referencia al perceptrón de una capa de Rosenblatt. Este perceptrón posee muy buena convergencia sin embargo requiere que en el espacio paramétrico las clases tengan separabilidad lineal. Para obtener esta separabilidad lineal, las etapas anteriores del PCNC, el extractor de propiedades y el codificador, convierten el espacio paramétrico de una imagen que es representado por el brillo de todos los píxeles de ésta, a un espacio paramétrico de mayor dimensión. En general se tiene un espacio paramétrico de dimensión $W\cdot H$ convertido a otro de dimensión $N$, donde $W$ y $H$ son el ancho y el alto en píxeles de las imágenes a procesar por el PCNC y $N$ es el parámetro del PCNC igual a la dimensión del vector $V'$. Este procedimiento descrito mejora considerablemente la separabilidad lineal del espacio paramétrico que representa la imagen y el objeto que esta contiene.

En la Fig. \ref{fig:liraDividido} se presenta de nuevo la estructura del clasificador neuronal LIRA pero dividiéndolo. Obsérvese que las primeras tres capas $S$, $I$ y $A$ cumplen la función de un extractor de propiedades al ser las entradas respectivas de cada grupo de la capa $I$ seleccionadas aleatoriamente dentro de un rectángulo posicionado aleatoriamente en la imagen (Sec. \ref{sec:LIRAestructura}). En cambio, las salidas de la capa $A$ y la capa $R$ en su totalidad, cumplen la función propia del clasificador neuronal cuya estructura está basada como ya se explicó en el perceptrón. De lo que se trata es de utilizar esta segunda parte de la estructura junto con el extractor de propiedades y el codificador (Fig. \ref{fig:PCNC}). Es decir, respecto del clasificador LIRA, se sustituyen las capas $S$, $I$ y $A$ por los dos bloques previamente descritos del PCNC. Debe notarse que con esta sustitución, la capa $A$ del clasificador neuronal pasa a contener exactamente al vector $V'$ por lo cuál debe tener $N$ elementos.

\begin{figure}[h]
\begin{center} 
\includegraphics[width=0.75\textwidth]
{figuras/liragsEspDividida.png}
\end{center}
\caption[Clasificador neuronal LIRA dividido.]{Clasificador neuronal LIRA dividido en dos partes según su función partículas: extractor de propiedades y clasificador.}\label{fig:liraDividido}
\end{figure}

Una vez que se ha descrito con todo detalle la estructura del PCNC se explicará su proceso de entrenamiento.

\section{Proceso de entrenamiento}
De acuerdo a las similitudes entre las estructuras del PCNC y del clasificador neuronal LIRA se tiene que la única parte de ambos que varia durante el proceso de entrenamiento son las conexiones entre las capas $A$ y R, por lo tanto el proceso de entrenamiento descrito para el clasificador LIRA (Sec. \ref{sec:LIRAentrenamiento}) funciona igual para el PCNC y por lo tanto es aplicado. El proceso de codificación de las imágenes aplicado a LIRA es válido para el PCNC por lo que se aplica también. Esto se debe a que cada imagen tendrá un vector $V'$ que codifica sus propiedades extraídas por lo cuál pueden usarse éstas a través de $V'$ en lugar de la imagen con propósitos de entrenamiento ahorrando importantes recursos de computo y de tiempo en el proceso.

\section{Distorsiones}\label{sec:PCNCdistor}
De forma similar que con el clasificador neuronal LIRA y con el objetivo de ampliar el conjunto de imágenes destinadas para el entrenamiento del PCNC, se consideró la aplicación de distorsiones sobre las imágenes normalizadas originales. Atendiendo a que el PCNC no es sensible a desplazamientos cartesianos de la imagen, sólo se aplicaron distorsiones angulares (Fig. \ref{fig:distorsionesTeta}). Estas distorsiones aplicadas sobre las imágenes, representan pequeñas variaciones sobre la exacta alineación de las piezas con respecto al eje horizontal que pasa por el centro de la imagen. Por esto se realizaron experimentos con diversas distorsiones angulares. Estos experimentos se explican en el siguiente capítulo, en la Sección \ref{ssec:PCNCdistor}.

Para realizar estas distorsiones se ha utilizado el mismo método de creación de imágenes distorsionadas que para el clasificador LIRA. Se consideró la creación de tales distorsiones en pares, con un mismo valor absoluto angular, pero con signos opuestos.

\begin{figure}[!h]
\begin{center} \includegraphics[
width=1.8in
]{figuras/distorsionesTeta.png}\end{center}
\caption[Distorsiones para ampliar el conjunto de entrenamiento.]{Ejemplo de una distorsión angular para las imágenes del conjunto de entrenamiento destinadas al PCNC.}
\label{fig:distorsionesTeta}
\end{figure}

\section{Discusión}\label{sec:PCNCdiscu}
Se ha visto que el clasificador PCNC es igual que el LIRA en cuando a
su método de clasificación, variando en ambos la forma en que se crean
o extraen las propiedades de la imagen a clasificar. Es entonces en
los procesos de extracción de propiedades y de codificación donde está
la diferencia entre el PCNC y LIRA. Esta diferencia tiene dos
características de importancia en el PCNC, una de éstas es la capacidad de
aplicar y probar diversos métodos de extracción de puntos específicos
y no limitarse únicamente a niveles de brillo a través de un umbral,
abriendo paso de esta manera a las posibilidades que ofrece el preprocesamiento de las imágenes a clasificar; la otra característica medular es la
consideración explícita que lleva a cabo el codificador sobre la posición de las propiedades encontradas en la imagen.

La principal desventaja del PCNC sobre el clasificador LIRA está en
sus mayores requerimientos de cómputo debido a la necesidad de
realizar gran cantidad de cálculos con vectores durante el proceso de
codificación de cada imagen. Comparando la etapa de extracción de propiedades de LIRA y del PCNC se observa que ambos ubican ventanas aleatoriamente en la imagen de entrada, el número de puntos de cada una de ellas puede ser similar, sin embargo, mientras la cantidad total de ventanas aleatorias en LIRA será igual al número de grupos en la capa $I$, que es un parámetro de este clasificador del orden de $100 000$ para la tarea de reconocimiento que nos ocupa \cite{Gengis2004}, se tiene que en el PCNC el número de tales ventanas será el número de puntos específicos extraídos de la imagen multiplicado por el parámetro $S$, y dado que este parámetro está entre $1000$ y $10 000$ \cite{Kussul2006IEEE}, tenemos que para el caso de $S=1000$ con $100$ puntos específicos igualamos los requerimientos del clasificador LIRA y en el orden en que este último número sea rebasado lo serán los requerimientos del PCNC respecto de LIRA en términos generales. Si consideramos que las imágenes normalizadas con que se ha trabajado (Sec. \ref{ssec:ImN}) tienen dimensión de $100\times 100$ como mínimo, igual a $10 000$ píxeles se tiene que el número de puntos específicos para igualar los requerimientos de LIRA deberán ser de aproximadamente el 1\%. Esto lleva a intentar mejorar el método de selección de puntos específicos o a tener que trabajar con las imágenes normalizadas reducidas cierta escala. Por lo anterior, de usarse el tamaño original de las imágenes, el método de selección de puntos específicos por umbral arrojará gran porcentaje de puntos respecto al total de píxeles de la imagen por lo que los requerimientos computacionales y de tiempo crecerán tanto que se violarán los principios de economía establecidos para las microfábricas y el SVT (Sec. \ref{sec:mF} y \ref{sec:SVT}). El inconveniente anterior se resolvió utilizando el umbral de gradiente de brillo (extracción de contornos), lo cual ha reducido el número de puntos específicos significativamente sin que se haya traducido en reducción de las propiedades que posibilitan la adecuada clasificación de las imágenes. Prueba de lo anterior se presenta en el capítulo siguiente y último.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "tesis"
%%% End: 


